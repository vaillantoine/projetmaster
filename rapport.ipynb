{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from code import *\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:48:28.361296100Z",
     "start_time": "2024-01-19T12:48:28.086292400Z"
    }
   },
   "id": "524c55fa7eb060cb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Création du dataset et chargement dans le DataLoader\n",
    "la fonction `gen_csv(img_dir, path_csv)` génère le fichier csv des labels selon les dossier des images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afd7f16454838e20"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"label_dir\": \"./labels\",\n",
    "    \"img_dir\": \"./img\",\n",
    "    \"optimizer\":\"SGD\",\n",
    "    \"learning_rate\":0.01,\n",
    "    \"epoch\":50,\n",
    "    \"loss\":\"cross_entropy\",\n",
    "    \"batch_size\":16,\n",
    "    \"device\":\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"path_config\":\"./config.json\", # PATH TO CHANGE\n",
    "    \"loss_history\" : {\"train\":[],\n",
    "                      \"val\": [],\n",
    "                      },\n",
    "    \"overall_time\": 0,\n",
    "    \"transforms\": transforms.Compose([\n",
    "        transforms.Resize((480,640)),\n",
    "    ])\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:49:06.860694800Z",
     "start_time": "2024-01-19T12:49:06.845062200Z"
    }
   },
   "id": "c07049c9e94f6a66"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             name  label\n",
      "0              nobody/nobody0.jpg      0\n",
      "1           nobody/nobody1000.jpg      0\n",
      "2           nobody/nobody1001.jpg      0\n",
      "3           nobody/nobody1002.jpg      0\n",
      "4           nobody/nobody1003.jpg      0\n",
      "...                           ...    ...\n",
      "2178     people/peopleimage10.jpg      2\n",
      "2179     people/peopleimage11.jpg      2\n",
      "2180  people/peopleimagecompr.jpg      2\n",
      "2181      people/peopletest12.jpg      2\n",
      "2182             people/peopletrj      2\n",
      "\n",
      "[2183 rows x 2 columns]\n",
      "\n",
      "\n",
      "Net(\n",
      "  (stack_conv_relu_pool): Sequential(\n",
      "    (0): Conv2d(3, 8, kernel_size=(5, 5), stride=(3, 3), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (stack_fullyconnected): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=8320, out_features=640, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=640, out_features=107, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=107, out_features=18, bias=True)\n",
      "    (6): ReLU()\n",
      "    (7): Linear(in_features=18, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "Nombre de paramètres : 5420940\n"
     ]
    }
   ],
   "source": [
    "## Dataset\n",
    "data = CustomImageDataset(CONFIG[\"label_dir\"], CONFIG[\"img_dir\"], transform=CONFIG[\"transforms\"])\n",
    "\n",
    "## DataLoader\n",
    "test_prop = 0.1\n",
    "val_prop = 0.1\n",
    "data, test_set = random_split(data, [1 - test_prop, test_prop])\n",
    "train_set, val_set = random_split(data, [1 - val_prop, val_prop])\n",
    "train_dataloader = DataLoader(train_set, batch_size=CONFIG[\"batch_size\"], shuffle=True)\n",
    "val_dataloader = DataLoader(val_set, batch_size=CONFIG[\"batch_size\"], shuffle=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size=CONFIG[\"batch_size\"], shuffle=True)\n",
    "CONFIG[\"n_train\"] = len(train_dataloader)\n",
    "CONFIG[\"n_val\"] = len(val_dataloader)\n",
    "\n",
    "## Network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.stack_conv_relu_pool = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=5, stride=3, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.stack_fullyconnected = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(8320, 640),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(640, 107),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(107, 18),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(18, 3),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stack_conv_relu_pool(x)\n",
    "        logits = self.stack_fullyconnected(x)\n",
    "        return logits\n",
    "\n",
    "net = Net().to(CONFIG[\"device\"])\n",
    "print(\"\\n\")\n",
    "print(net)\n",
    "nombre_parametres = sum(p.numel() for p in net.parameters())\n",
    "print(f\"Nombre de paramètres : {nombre_parametres}\")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(CONFIG[\"device\"])\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=CONFIG[\"learning_rate\"])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:49:14.174930800Z",
     "start_time": "2024-01-19T12:49:13.342525900Z"
    }
   },
   "id": "90553284d3040243"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training loop"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7119caa4f70cca66"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asury\\Documents\\Cours\\3A\\Master\\projet\\venv\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train loss = avg 1.0410 || Valid loss = avg 0.9898\n",
      "Time :4.0mn 8.5s\n",
      "Epoch 1: Train loss = avg 0.9424 || Valid loss = avg 0.8973\n",
      "Time :3.0mn 30.4s\n",
      "Epoch 2: Train loss = avg 0.9028 || Valid loss = avg 0.9081\n",
      "Time :4.0mn 39.9s\n",
      "Epoch 3: Train loss = avg 0.8875 || Valid loss = avg 0.9361\n",
      "Time :1.0mn 41.8s\n",
      "Epoch 4: Train loss = avg 0.8788 || Valid loss = avg 0.8919\n",
      "Time :2.0mn 5.0s\n",
      "Epoch 5: Train loss = avg 0.8760 || Valid loss = avg 0.9473\n",
      "Time :2.0mn 9.4s\n",
      "Epoch 6: Train loss = avg 0.8730 || Valid loss = avg 0.9635\n",
      "Time :1.0mn 27.2s\n",
      "Epoch 7: Train loss = avg 0.8718 || Valid loss = avg 0.9176\n",
      "Time :1.0mn 43.4s\n",
      "Epoch 8: Train loss = avg 0.8698 || Valid loss = avg 0.8691\n",
      "Time :1.0mn 24.0s\n",
      "Epoch 9: Train loss = avg 0.8700 || Valid loss = avg 0.9034\n",
      "Time :1.0mn 23.6s\n",
      "Epoch 10: Train loss = avg 0.8693 || Valid loss = avg 0.8755\n",
      "Time :1.0mn 31.3s\n",
      "Epoch 11: Train loss = avg 0.8683 || Valid loss = avg 0.9483\n",
      "Time :1.0mn 23.7s\n",
      "Epoch 12: Train loss = avg 0.8684 || Valid loss = avg 0.8307\n",
      "Time :1.0mn 33.0s\n",
      "Epoch 13: Train loss = avg 0.8651 || Valid loss = avg 0.8644\n",
      "Time :1.0mn 27.3s\n",
      "Epoch 14: Train loss = avg 0.8660 || Valid loss = avg 0.8654\n",
      "Time :1.0mn 27.7s\n",
      "Epoch 15: Train loss = avg 0.8605 || Valid loss = avg 0.9517\n",
      "Time :1.0mn 24.1s\n",
      "Epoch 16: Train loss = avg 0.8548 || Valid loss = avg 0.8941\n",
      "Time :1.0mn 21.2s\n",
      "Epoch 17: Train loss = avg 0.8400 || Valid loss = avg 0.8865\n",
      "Time :1.0mn 31.9s\n",
      "Epoch 18: Train loss = avg 0.8080 || Valid loss = avg 0.8659\n",
      "Time :1.0mn 28.9s\n",
      "Epoch 19: Train loss = avg 0.7464 || Valid loss = avg 0.8410\n",
      "Time :1.0mn 27.7s\n",
      "Epoch 20: Train loss = avg 0.7111 || Valid loss = avg 0.7167\n",
      "Time :1.0mn 30.4s\n",
      "Epoch 21: Train loss = avg 0.6902 || Valid loss = avg 0.7441\n",
      "Time :1.0mn 22.7s\n",
      "Epoch 22: Train loss = avg 0.7074 || Valid loss = avg 0.7329\n",
      "Time :1.0mn 22.5s\n",
      "Epoch 23: Train loss = avg 0.6911 || Valid loss = avg 0.7303\n",
      "Time :1.0mn 24.9s\n",
      "Epoch 24: Train loss = avg 0.6800 || Valid loss = avg 0.9189\n",
      "Time :1.0mn 23.7s\n",
      "Epoch 25: Train loss = avg 0.6819 || Valid loss = avg 0.6474\n",
      "Time :1.0mn 23.6s\n",
      "Epoch 26: Train loss = avg 0.6698 || Valid loss = avg 0.6638\n",
      "Time :1.0mn 25.6s\n",
      "Epoch 27: Train loss = avg 0.6695 || Valid loss = avg 0.6828\n",
      "Time :1.0mn 31.2s\n",
      "Epoch 28: Train loss = avg 0.6698 || Valid loss = avg 0.7064\n",
      "Time :1.0mn 23.0s\n",
      "Epoch 29: Train loss = avg 0.6640 || Valid loss = avg 0.7620\n",
      "Time :1.0mn 23.9s\n",
      "Epoch 30: Train loss = avg 0.6671 || Valid loss = avg 0.7262\n",
      "Time :1.0mn 30.2s\n",
      "Epoch 31: Train loss = avg 0.6642 || Valid loss = avg 0.7294\n",
      "Time :1.0mn 22.6s\n",
      "Epoch 32: Train loss = avg 0.6497 || Valid loss = avg 0.6789\n",
      "Time :1.0mn 20.0s\n",
      "Epoch 33: Train loss = avg 0.6542 || Valid loss = avg 0.7174\n",
      "Time :1.0mn 22.5s\n",
      "Epoch 34: Train loss = avg 0.6374 || Valid loss = avg 0.8960\n",
      "Time :1.0mn 22.0s\n",
      "Epoch 35: Train loss = avg 0.6686 || Valid loss = avg 0.6610\n",
      "Time :1.0mn 21.4s\n",
      "Epoch 36: Train loss = avg 0.6447 || Valid loss = avg 0.7343\n",
      "Time :1.0mn 21.5s\n",
      "Epoch 37: Train loss = avg 0.6295 || Valid loss = avg 0.5938\n",
      "Time :1.0mn 21.0s\n",
      "Epoch 38: Train loss = avg 0.6211 || Valid loss = avg 0.6420\n",
      "Time :1.0mn 21.5s\n",
      "Epoch 39: Train loss = avg 0.6243 || Valid loss = avg 0.6804\n",
      "Time :1.0mn 21.7s\n",
      "Epoch 40: Train loss = avg 0.6253 || Valid loss = avg 0.7541\n",
      "Time :1.0mn 21.0s\n",
      "Epoch 41: Train loss = avg 0.6254 || Valid loss = avg 0.6582\n",
      "Time :1.0mn 21.4s\n",
      "Epoch 42: Train loss = avg 0.6194 || Valid loss = avg 0.6310\n",
      "Time :1.0mn 21.5s\n",
      "Epoch 43: Train loss = avg 0.6019 || Valid loss = avg 0.6397\n",
      "Time :1.0mn 21.4s\n",
      "Epoch 44: Train loss = avg 0.6146 || Valid loss = avg 0.6629\n",
      "Time :1.0mn 20.5s\n",
      "Epoch 45: Train loss = avg 0.5866 || Valid loss = avg 0.6483\n",
      "Time :1.0mn 22.6s\n",
      "Epoch 46: Train loss = avg 0.5884 || Valid loss = avg 0.7559\n",
      "Time :1.0mn 21.3s\n",
      "Epoch 47: Train loss = avg 0.5772 || Valid loss = avg 0.6911\n",
      "Time :1.0mn 21.1s\n",
      "Epoch 48: Train loss = avg 0.5709 || Valid loss = avg 0.6936\n",
      "Time :1.0mn 21.3s\n",
      "Epoch 49: Train loss = avg 0.5516 || Valid loss = avg 0.5837\n",
      "Time :1.0mn 21.0s\n"
     ]
    }
   ],
   "source": [
    "for e in range(CONFIG[\"epoch\"]):\n",
    "\n",
    "    #--- Init ---#\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    clk = time.time()\n",
    "    \n",
    "    #--- Training ---#\n",
    "    net.train()\n",
    "    for data in train_dataloader:\n",
    "\n",
    "        #--- get image and label from data ---#\n",
    "        train_features, train_labels = data\n",
    "        train_features = train_features / 255\n",
    "        if torch.cuda.is_available():\n",
    "          train_features, train_labels = train_features.cuda(), train_labels.cuda()\n",
    "        #--- reset optimizer ---#\n",
    "        optimizer.zero_grad()\n",
    "        #--- prediction ---#\n",
    "        pred = net(train_features)\n",
    "        #--- loss function ---#\n",
    "        loss = criterion(pred, train_labels)\n",
    "        #--- backpropagation ---#\n",
    "        loss.backward()\n",
    "        #--- Network optimization ---#\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    #--- Validation ---#\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in val_dataloader:\n",
    "\n",
    "            #--- get image and label from data ---#\n",
    "            val_features, val_labels = next(iter(val_dataloader))\n",
    "            val_features = val_features / 255\n",
    "            if torch.cuda.is_available():\n",
    "                val_features, val_labels = val_features.cuda(), val_labels.cuda()\n",
    "            #--- prediction ---#\n",
    "            pred = net(val_features)\n",
    "            #--- loss function ---#\n",
    "            loss = criterion(pred, val_labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    #--- Epoch results ---#\n",
    "    train_loss /= CONFIG[\"n_train\"]\n",
    "    val_loss /= CONFIG[\"n_val\"]\n",
    "    clk = time.time() - clk\n",
    "    CONFIG[\"overall_time\"] += clk\n",
    "    CONFIG[\"loss_history\"][\"train\"].append(train_loss)\n",
    "    CONFIG[\"loss_history\"][\"val\"].append(val_loss)\n",
    "    print('Epoch {}: Train loss = avg {:0.4f} || Valid loss = avg {:0.4f}\\nTime :{:0.1f}mn {:0.1f}s\\n'.format(e,train_loss,val_loss,clk//60,clk%60))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T14:09:40.142496Z",
     "start_time": "2024-01-19T12:49:20.859058400Z"
    }
   },
   "id": "f8ee44780a34d863"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(),\"./train50.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T14:16:29.722083500Z",
     "start_time": "2024-01-19T14:16:29.614403300Z"
    }
   },
   "id": "753da2e7efd35961"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "def plot_training_curves(config):\n",
    "    \"\"\"Save training curves of a network.\"\"\"\n",
    "\n",
    "    #--- Init ---#\n",
    "    n_epoch = config[\"epoch\"]\n",
    "    epochs = np.arange(1,n_epoch+1)\n",
    "    fig = plt.figure(figsize=(19.2,10.8),dpi=100)\n",
    "\n",
    "    #--- Plot ---#\n",
    "    plt.plot(epochs,config[\"loss_history\"][\"train\"],label=\"Train\")\n",
    "    plt.plot(epochs,config[\"loss_history\"][\"val\"],label=\"Val\")\n",
    "    plt.title(\"Loss curves\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "def evaluate_model(net,test_dataloader,criterion,config):\n",
    "  \"\"\"Evaluate the model on a given test set.\"\"\"\n",
    "\n",
    "  #--- Init ---#\n",
    "  test_loss = 0\n",
    "  count = 0\n",
    "  n_test = len(test_dataloader)\n",
    "  config[\"n_test\"] = n_test\n",
    "\n",
    "  #--- Evaluate ---#\n",
    "  net.eval()\n",
    "  with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "\n",
    "      #--- get image and label from data ---#\n",
    "      data, labels = data\n",
    "      data = data / 255\n",
    "      if torch.cuda.is_available():\n",
    "        data, labels = data.cuda(), labels.cuda()\n",
    "      #--- prediction ---#\n",
    "      pred = net(data)\n",
    "      #--- loss function ---#\n",
    "      loss = criterion(pred, labels)\n",
    "      #--- accuracy ---#\n",
    "      y = torch.argmax(pred)\n",
    "      count += (y == labels.item())\n",
    "\n",
    "  #--- Results ---#\n",
    "  count = count / config[\"n_test\"]\n",
    "  count *= 100\n",
    "  config[\"loss_history\"][\"test\"] = count.item()\n",
    "  print(\"Test accuracy: {:0.2f}%\".format(count))\n",
    "\n",
    "  return config\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\"\"\" Plot training curves \"\"\"\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "plot_training_curves(CONFIG)\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\"\"\" Evaluate network on test set \"\"\"\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "CONFIG = evaluate_model(net,test_dataloader,criterion,CONFIG)\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\"\"\" Save results \"\"\"\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "#--- Save CONFIG ---#\n",
    "with open(\"save_config.json\",'w') as f:\n",
    "    json.dump(CONFIG, f, indent=4)\n",
    "\n",
    "#--- Save training curves ---#\n",
    "# ... #\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------#"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-19T14:27:10.890616Z"
    }
   },
   "id": "d671b2b3b554b2f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
